{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from  sklearn.utils import parallel_backend\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_images_and_labels(path, file_ending= \"jpg\"):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    for directory in Path(path).glob('*'):\n",
    "        for p in directory.glob(\"*.\" + file_ending):\n",
    "            paths.append(p)\n",
    "            labels.append(directory.name)\n",
    "\n",
    "    return paths, labels\n",
    "\n",
    "\n",
    "\n",
    "fruit_image_paths, fruit_image_labels = get_images_and_labels(\"data/FIDS30/\")\n",
    "\n",
    "traffic_sign_image_paths_train, traffic_sign_image_labels_train = get_images_and_labels(\"data/TrafficSigns/train\", \"ppm\")\n",
    "traffic_sign_image_paths_test, traffic_sign_image_labels_test = get_images_and_labels(\"data/TrafficSigns/test\",\"ppm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def color_histogram_features(images):\n",
    "   \n",
    "    # Next, we extract a few more features using OpenCV\n",
    "    dataOpenCV_1D = []\n",
    "    dataOpenCV_2D = []\n",
    "    dataOpenCV_3D = []\n",
    "\n",
    "    # use our own simple function to flatten the 2D arrays\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "    for filepath in tqdm(images):\n",
    "\n",
    "        # the easiest way would to do the following:\n",
    "        # imageOpenCV = cv2.imread(imagePath + fileName)\n",
    "\n",
    "        # However, we have the same issue as before, and it is more difficult in OpenCV to convert to an RGB image\n",
    "        # Thus we do this using PIL, and then convert to OpenCV ....\n",
    "        imagePIL = Image.open(filepath)\n",
    "        imagePIL = imagePIL.convert('RGB')\n",
    "        imageOpenCV = np.array(imagePIL)\n",
    "        # Convert RGB to BGR\n",
    "        imageOpenCV = imageOpenCV[:, :, ::-1].copy()\n",
    "\n",
    "        # Now we split the image in the three channels, B / G / R\n",
    "        chans = cv2.split(imageOpenCV)\n",
    "        colors = (\"b\", \"g\", \"r\")\n",
    "\n",
    "        # First we do also features per channel, but this time, we aggregate them into a smaller number of bins\n",
    "        # I.e. we do not have 256 values per channel, but less\n",
    "        featuresOpenCV_1D = []\n",
    "        bins_1D = 64\n",
    "        for (chan, color) in zip(chans, colors):  # we compute the histogram over each channel\n",
    "            histOpenCV = cv2.calcHist([chan], [0], None, [bins_1D], [0, 256])\n",
    "            featuresOpenCV_1D.extend(histOpenCV)\n",
    "        featureVectorOpenCV_1D = flatten(featuresOpenCV_1D)  # and append this to our feature vector\n",
    "\n",
    "        dataOpenCV_1D.append(featureVectorOpenCV_1D)  # now we append the feature vector to the dataset so far\n",
    "\n",
    "        if (len(featureVectorOpenCV_1D) != bins_1D * 3):  # sanity check, in case we had a wrong number of channels...\n",
    "            print(\"Unexpected length of feature vector: \" + str(len(featureVectorOpenCV_1D)) + \" in file: \" + filepath)\n",
    "\n",
    "        # Next - features that look at two channels at the same time\n",
    "        # E.g. we look at when green and blue have both \"high values\"\n",
    "        # We reduce the size of bins further, to not have a too long feature vector\n",
    "        featuresOpenCV_2D = []\n",
    "        bins2D = 16\n",
    "        # look at all combinations of channels (R & B, R & G, B & G)\n",
    "        featuresOpenCV_2D.extend(cv2.calcHist([chans[1], chans[0]], [0, 1], None, [bins2D, bins2D], [0, 256, 0, 256]))\n",
    "        featuresOpenCV_2D.extend(cv2.calcHist([chans[1], chans[2]], [0, 1], None, [bins2D, bins2D], [0, 256, 0, 256]))\n",
    "        featuresOpenCV_2D.extend(cv2.calcHist([chans[0], chans[2]], [0, 1], None, [bins2D, bins2D], [0, 256, 0, 256]))\n",
    "        # and add that to our dataset\n",
    "        featureVectorOpenCV_2D = flatten(featuresOpenCV_2D)\n",
    "        dataOpenCV_2D.append(featureVectorOpenCV_2D)\n",
    "\n",
    "        # finally, we look at all three channels at the same time.\n",
    "        # We further reduce our bin size, because otherwise, this would become very large...\n",
    "        featuresOpenCV_3D = cv2.calcHist([imageOpenCV], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "        # append to our dataset\n",
    "        featureVectorOpenCV_3D = featuresOpenCV_3D.flatten()\n",
    "        dataOpenCV_3D.append(featureVectorOpenCV_3D)\n",
    "\n",
    "    return dataOpenCV_1D, dataOpenCV_2D, dataOpenCV_3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bovw(images,kmeans):\n",
    "    \n",
    "    # let's use opencv to extract the features\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    features_all = []\n",
    "    feature_counts = []\n",
    "\n",
    "    # for every path extract the 128 sift descriptors\n",
    "    for path in tqdm(images):\n",
    "        img = cv2.imread(str(path), 0)\n",
    "        _, features = sift.detectAndCompute(img, None)\n",
    "        if features is not None:\n",
    "            feature_counts.append(features.shape[0])\n",
    "            features_all.append(features)\n",
    "        else:\n",
    "            feature_counts.append(0)\n",
    "\n",
    "    features_all = np.vstack(features_all)\n",
    "    display(\"Do KMeans clustering\")\n",
    "    n_clusters = 100\n",
    "    # assign a cluster/word to every feature that SIFT found\n",
    "    if kmeans is None:\n",
    "        kmeans = MiniBatchKMeans(n_clusters = n_clusters)\n",
    "        kmeans.fit(features_all)\n",
    "        clusters = kmeans.predict(features_all)\n",
    "    else:\n",
    "        clusters = kmeans.predict(features_all)\n",
    "\n",
    "    histogram = np.zeros((len(images), n_clusters))\n",
    "    i = 0\n",
    "    for image_idx, count in enumerate(feature_counts):\n",
    "        for c in range(i, i+count):\n",
    "            histogram[image_idx][clusters[c]] += 1\n",
    "        i += count\n",
    "\n",
    "    histogram = StandardScaler().fit_transform(histogram)\n",
    "\n",
    "    return histogram, kmeans\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers \n",
    "\n",
    "We are using three different classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, params ) :\n",
    "   \n",
    "    results = []\n",
    "\n",
    "    for model_name, param in params.items():\n",
    "        display(\"Hyperparameter search for model :\" + model_name)\n",
    "        clf = GridSearchCV(param['model'], param['parameters'], scoring='accuracy', cv=3, n_jobs=5)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        predict_duration = time.time() - start_time\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'params': '_'.join([f'{k}={v}' for k, v in clf.best_params_.items()]),\n",
    "            'y_pred': y_pred,\n",
    "            'y_true': y_test,\n",
    "            'train_duration': clf.refit_time_,\n",
    "            'predict_duration': predict_duration,\n",
    "            'accuracy': accuracy\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'RandomForrest': {\n",
    "        'model': RandomForestClassifier(n_jobs = 2,random_state=1234),\n",
    "        'parameters': {\n",
    "            'n_estimators': [10, 25, 50, 100, 200],\n",
    "            'max_depth': [4, 8, 15, 20]\n",
    "        }\n",
    "    },\n",
    "    'MLP': {\n",
    "        'model': MLPClassifier( max_iter = 500, random_state=1234),\n",
    "        'parameters': {\n",
    "            'hidden_layer_sizes': [\n",
    "                (64,),\n",
    "                (128,),\n",
    "                (128, 64),\n",
    "            ],\n",
    "            'activation': ['tanh'],\n",
    "            'alpha': [0.01, 0.1],\n",
    "            'learning_rate' : ['constant'],\n",
    "            'learning_rate_init' : [ 0.01, 0.001]\n",
    "        }\n",
    "    },\n",
    "    'k-NN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'parameters': {'n_neighbors': [3, 5, 10, 30, 50]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Histogram Classification Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculate Histograms for Fruits!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 971/971 [00:55<00:00, 17.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Feature extraction took: 55.29846501350403 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "display(\"Calculate Histograms for Fruits!\")\n",
    "feature_extraction_start_time = time.time()\n",
    "opencv_1D, opencv_2D, opencv_3D = color_histogram_features(fruit_image_paths)\n",
    "duration =  time.time() - feature_extraction_start_time\n",
    "display(\"Feature extraction took: \" + str(duration) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D Train/test split'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training on single channel histogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2D Train/test split'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training on 2D channel historgrams'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'3D Train/test split'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training on 3D channel historgrams'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with parallel_backend('threading'):\n",
    "    display('1D Train/test split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(opencv_1D, fruit_image_labels, test_size=0.25, random_state=1234)\n",
    "    display('Training on single channel histogram')\n",
    "    results_1d = train_test(X_train, X_test, y_train, y_test,params)\n",
    "    for r in results_1d:\n",
    "        r['features'] = f'hist1D'\n",
    "\n",
    "    display('2D Train/test split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(opencv_2D, fruit_image_labels, test_size=0.25, random_state=1234)\n",
    "    display('Training on 2D channel historgrams')\n",
    "    results_2d = train_test(X_train, X_test, y_train, y_test,params)\n",
    "    for r in results_2d:\n",
    "        r['features'] = f'hist2D'\n",
    "\n",
    "    display('3D Train/test split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(opencv_3D, fruit_image_labels, test_size=0.25, random_state=1234)\n",
    "    display('Training on 3D channel historgrams')\n",
    "    results_3d = train_test(X_train, X_test, y_train, y_test,params)\n",
    "    for r in results_3d:\n",
    "        r['features'] = f'hist3D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_hist_results_df = pd.DataFrame(results_1d + results_2d + results_3d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOVW Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculate BOVW for Fruits!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 728/728 [03:43<00:00,  3.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Do KMeans clustering'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [01:09<00:00,  3.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Do KMeans clustering'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Feature extraction took: 374.25863695144653 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Calculate BOVW for Fruits!\")\n",
    "\n",
    "train_images, test_images, y_train, y_test = train_test_split(fruit_image_paths, fruit_image_labels, test_size=0.25, random_state=1234)\n",
    "\n",
    "feature_extraction_start_time = time.time()\n",
    "X_train, kmeans = bovw(train_images, None)\n",
    "X_test, kmeans = bovw(test_images, kmeans=kmeans)\n",
    "duration =  time.time() - feature_extraction_start_time\n",
    "\n",
    "display(\"Feature extraction took: \" + str(duration) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    results = train_test(X_train, X_test, y_train, y_test, params )\n",
    "    for r in results:\n",
    "        r['features'] = f'bovw'\n",
    "    fruits_bovw_results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "      <th>train_duration</th>\n",
       "      <th>predict_duration</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=100</td>\n",
       "      <td>[pineapples, apples, plums, raspberries, banan...</td>\n",
       "      <td>[bananas, mangos, cherries, blueberries, olive...</td>\n",
       "      <td>0.342589</td>\n",
       "      <td>0.106378</td>\n",
       "      <td>0.205761</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=tanh_alpha=0.1_hidden_layer_sizes=(...</td>\n",
       "      <td>[bananas, apricots, olives, plums, bananas, pe...</td>\n",
       "      <td>[bananas, mangos, cherries, blueberries, olive...</td>\n",
       "      <td>2.321604</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.341564</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=10</td>\n",
       "      <td>[bananas, bananas, apples, blueberries, banana...</td>\n",
       "      <td>[bananas, mangos, cherries, blueberries, olive...</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.037328</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                             params  \\\n",
       "0  RandomForrest                      max_depth=20_n_estimators=100   \n",
       "1            MLP  activation=tanh_alpha=0.1_hidden_layer_sizes=(...   \n",
       "2           k-NN                                     n_neighbors=10   \n",
       "\n",
       "                                              y_pred  \\\n",
       "0  [pineapples, apples, plums, raspberries, banan...   \n",
       "1  [bananas, apricots, olives, plums, bananas, pe...   \n",
       "2  [bananas, bananas, apples, blueberries, banana...   \n",
       "\n",
       "                                              y_true  train_duration  \\\n",
       "0  [bananas, mangos, cherries, blueberries, olive...        0.342589   \n",
       "1  [bananas, mangos, cherries, blueberries, olive...        2.321604   \n",
       "2  [bananas, mangos, cherries, blueberries, olive...        0.003317   \n",
       "\n",
       "   predict_duration  accuracy features  \n",
       "0          0.106378  0.205761     bovw  \n",
       "1          0.000655  0.341564     bovw  \n",
       "2          0.037328  0.181070     bovw  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits_bovw_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Histogram Classification Traffic Signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculate Histograms for Traffic Signs!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6058/6058 [00:06<00:00, 923.19it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Feature extraction took: 6.6029579639434814 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traffic_image_paths = traffic_sign_image_paths_train+traffic_sign_image_paths_test\n",
    "display(\"Calculate Histograms for Traffic Signs!\")\n",
    "feature_extraction_start_time = time.time()\n",
    "opencv_1D, opencv_2D, opencv_3D = color_histogram_features(traffic_image_paths)\n",
    "duration =  time.time() - feature_extraction_start_time\n",
    "display(\"Feature extraction took: \" + str(duration) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1D Train/test split'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training on single channel histogram'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2D Train/test split'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training on 2D channel historgrams'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'3D Train/test split'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training on 3D channel historgrams'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traffic_labels = traffic_sign_image_labels_train + traffic_sign_image_labels_test\n",
    "with parallel_backend('threading'):\n",
    "    display('1D Train/test split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(opencv_1D, traffic_labels, test_size=0.25, random_state=1234)\n",
    "    display('Training on single channel histogram')\n",
    "    results_1d = train_test(X_train, X_test, y_train, y_test,params)\n",
    "    for r in results_1d:\n",
    "        r['features'] = f'hist1D'\n",
    "\n",
    "    display('2D Train/test split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(opencv_2D, traffic_labels, test_size=0.25, random_state=1234)\n",
    "    display('Training on 2D channel historgrams')\n",
    "    results_2d = train_test(X_train, X_test, y_train, y_test,params)\n",
    "    for r in results_2d:\n",
    "        r['features'] = f'hist2D'\n",
    "\n",
    "    display('3D Train/test split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(opencv_3D, traffic_labels, test_size=0.25, random_state=1234)\n",
    "    display('Training on 3D channel historgrams')\n",
    "    results_3d = train_test(X_train, X_test, y_train, y_test,params)\n",
    "    for r in results_3d:\n",
    "        r['features'] = f'hist3D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_signs_hist_results_df = pd.DataFrame(results_1d + results_2d + results_3d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOVW Traffic Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculate BOVW for Traffic Signs!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4543/4543 [00:04<00:00, 1010.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Do KMeans clustering'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1515/1515 [00:01<00:00, 1011.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Do KMeans clustering'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Feature extraction took: 9.558998107910156 seconds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Calculate BOVW for Traffic Signs!\")\n",
    "\n",
    "train_images, test_images, y_train, y_test = train_test_split(traffic_image_paths, traffic_labels, test_size=0.25, random_state=1234)\n",
    "\n",
    "feature_extraction_start_time = time.time()\n",
    "X_train, kmeans = bovw(train_images, None)\n",
    "X_test, kmeans = bovw(test_images, kmeans=kmeans)\n",
    "duration =  time.time() - feature_extraction_start_time\n",
    "\n",
    "display(\"Feature extraction took: \" + str(duration) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :RandomForrest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :MLP'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hyperparameter search for model :k-NN'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    results = train_test(X_train, X_test, y_train, y_test, params )\n",
    "    for r in results:\n",
    "        r['features'] = f'bovw'\n",
    "    traffic_signs_bovw_results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plotConfusionMatrix(y_true, y_pred, classes, name=None, normalize=True,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = np.array(list(classes))[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title='Confusion Matrix',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    size = 6 if normalize else 9\n",
    "    thresh = 0.5 if normalize else cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\", size=size,\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if name is not None:\n",
    "        plt.savefig('./figures/' + name + '_cm.png', dpi=150)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " # print results\n",
    "def print_and_save_results(results, labels):\n",
    "    for i, r in results.iterrows():\n",
    "        classes = list(set(labels))\n",
    "        y_true = np.array([classes.index(y) for y in r['y_true']])\n",
    "        y_pred = np.array([classes.index(y) for y in r['y_pred']])\n",
    "        accuracy = sum(y_true == y_pred) / y_true.shape[0]\n",
    "        dataset_name = \"fruits\"\n",
    "        plotConfusionMatrix(\n",
    "            y_true=y_true,\n",
    "            y_pred=y_pred,\n",
    "            classes=classes,\n",
    "            name=f'{r[\"model\"]} {dataset_name} {r[\"features\"]} {r[\"params\"]}'\n",
    "        )\n",
    "\n",
    "\n",
    "        with open(f'scores/{r[\"model\"]} {dataset_name} {r[\"features\"]} {r[\"params\"]}.txt', 'w') as f:\n",
    "            f.write('model,features,parameters,accuracy\\n')\n",
    "            f.write(f'{r[\"model\"]},{r[\"features\"]},\"{r[\"params\"]}\",{accuracy}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_and_save_results(fruits_hist_results_df,fruit_image_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_duration</th>\n",
       "      <th>predict_duration</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=15_n_estimators=200</td>\n",
       "      <td>0.899194</td>\n",
       "      <td>0.112549</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>hist1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=relu_alpha=0.1_hidden_layer_sizes=(256,)_learning_rate=constant_learning_rate_init=0.001</td>\n",
       "      <td>4.715840</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.267490</td>\n",
       "      <td>hist1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=10</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>0.042981</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>hist1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=200</td>\n",
       "      <td>1.039364</td>\n",
       "      <td>0.122725</td>\n",
       "      <td>0.460905</td>\n",
       "      <td>hist2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=relu_alpha=0.1_hidden_layer_sizes=(256,)_learning_rate=constant_learning_rate_init=0.001</td>\n",
       "      <td>4.169756</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.440329</td>\n",
       "      <td>hist2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=10</td>\n",
       "      <td>0.073017</td>\n",
       "      <td>0.148042</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>hist2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=200</td>\n",
       "      <td>0.686426</td>\n",
       "      <td>0.105014</td>\n",
       "      <td>0.489712</td>\n",
       "      <td>hist3D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=tanh_alpha=1_hidden_layer_sizes=(256, 128)_learning_rate=adaptive_learning_rate_init=0.001</td>\n",
       "      <td>2.427944</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.411523</td>\n",
       "      <td>hist3D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=10</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.213992</td>\n",
       "      <td>hist3D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  \\\n",
       "0  RandomForrest   \n",
       "1  MLP             \n",
       "2  k-NN            \n",
       "3  RandomForrest   \n",
       "4  MLP             \n",
       "5  k-NN            \n",
       "6  RandomForrest   \n",
       "7  MLP             \n",
       "8  k-NN            \n",
       "\n",
       "                                                                                                  params  \\\n",
       "0  max_depth=15_n_estimators=200                                                                           \n",
       "1  activation=relu_alpha=0.1_hidden_layer_sizes=(256,)_learning_rate=constant_learning_rate_init=0.001     \n",
       "2  n_neighbors=10                                                                                          \n",
       "3  max_depth=20_n_estimators=200                                                                           \n",
       "4  activation=relu_alpha=0.1_hidden_layer_sizes=(256,)_learning_rate=constant_learning_rate_init=0.001     \n",
       "5  n_neighbors=10                                                                                          \n",
       "6  max_depth=20_n_estimators=200                                                                           \n",
       "7  activation=tanh_alpha=1_hidden_layer_sizes=(256, 128)_learning_rate=adaptive_learning_rate_init=0.001   \n",
       "8  n_neighbors=10                                                                                          \n",
       "\n",
       "   train_duration  predict_duration  accuracy features  \n",
       "0  0.899194        0.112549          0.271605  hist1D   \n",
       "1  4.715840        0.005972          0.267490  hist1D   \n",
       "2  0.020377        0.042981          0.123457  hist1D   \n",
       "3  1.039364        0.122725          0.460905  hist2D   \n",
       "4  4.169756        0.020465          0.440329  hist2D   \n",
       "5  0.073017        0.148042          0.172840  hist2D   \n",
       "6  0.686426        0.105014          0.489712  hist3D   \n",
       "7  2.427944        0.002454          0.411523  hist3D   \n",
       "8  0.014134        0.082800          0.213992  hist3D   "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "fruits_hist_results_df[[\"model\",\"params\", \"train_duration\", \"predict_duration\",\"accuracy\", \"features\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_and_save_results(fruits_bovw_results_df,fruit_image_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_duration</th>\n",
       "      <th>predict_duration</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=100</td>\n",
       "      <td>0.342589</td>\n",
       "      <td>0.106378</td>\n",
       "      <td>0.205761</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=tanh_alpha=0.1_hidden_layer_sizes=(64,)_learning_rate=constant_learning_rate_init=0.001</td>\n",
       "      <td>2.321604</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.341564</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=10</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.037328</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  \\\n",
       "0  RandomForrest   \n",
       "1  MLP             \n",
       "2  k-NN            \n",
       "\n",
       "                                                                                               params  \\\n",
       "0  max_depth=20_n_estimators=100                                                                        \n",
       "1  activation=tanh_alpha=0.1_hidden_layer_sizes=(64,)_learning_rate=constant_learning_rate_init=0.001   \n",
       "2  n_neighbors=10                                                                                       \n",
       "\n",
       "   train_duration  predict_duration  accuracy features  \n",
       "0  0.342589        0.106378          0.205761  bovw     \n",
       "1  2.321604        0.000655          0.341564  bovw     \n",
       "2  0.003317        0.037328          0.181070  bovw     "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "fruits_bovw_results_df[[\"model\",\"params\", \"train_duration\", \"predict_duration\",\"accuracy\", \"features\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Traffic Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_and_save_results(traffic_signs_hist_results_df, traffic_sign_image_labels_train+traffic_sign_image_labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_duration</th>\n",
       "      <th>predict_duration</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=200</td>\n",
       "      <td>2.295731</td>\n",
       "      <td>0.137406</td>\n",
       "      <td>0.893729</td>\n",
       "      <td>hist1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=tanh_alpha=1_hidden_layer_sizes=(256,)_learning_rate=adaptive_learning_rate_init=0.001</td>\n",
       "      <td>3.016250</td>\n",
       "      <td>0.029408</td>\n",
       "      <td>0.919472</td>\n",
       "      <td>hist1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=3</td>\n",
       "      <td>0.113536</td>\n",
       "      <td>0.794551</td>\n",
       "      <td>0.925413</td>\n",
       "      <td>hist1D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=200</td>\n",
       "      <td>2.252907</td>\n",
       "      <td>0.193570</td>\n",
       "      <td>0.932673</td>\n",
       "      <td>hist2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=tanh_alpha=0.01_hidden_layer_sizes=(256,)_learning_rate=constant_learning_rate_init=0.001</td>\n",
       "      <td>7.798414</td>\n",
       "      <td>0.101383</td>\n",
       "      <td>0.955116</td>\n",
       "      <td>hist2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=3</td>\n",
       "      <td>0.450569</td>\n",
       "      <td>1.795464</td>\n",
       "      <td>0.933993</td>\n",
       "      <td>hist2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=200</td>\n",
       "      <td>1.201391</td>\n",
       "      <td>0.106719</td>\n",
       "      <td>0.910231</td>\n",
       "      <td>hist3D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=tanh_alpha=1_hidden_layer_sizes=(256,)_learning_rate=adaptive_learning_rate_init=0.001</td>\n",
       "      <td>7.576664</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.948515</td>\n",
       "      <td>hist3D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=3</td>\n",
       "      <td>0.146073</td>\n",
       "      <td>1.210200</td>\n",
       "      <td>0.920132</td>\n",
       "      <td>hist3D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  \\\n",
       "0  RandomForrest   \n",
       "1  MLP             \n",
       "2  k-NN            \n",
       "3  RandomForrest   \n",
       "4  MLP             \n",
       "5  k-NN            \n",
       "6  RandomForrest   \n",
       "7  MLP             \n",
       "8  k-NN            \n",
       "\n",
       "                                                                                                 params  \\\n",
       "0  max_depth=20_n_estimators=200                                                                          \n",
       "1  activation=tanh_alpha=1_hidden_layer_sizes=(256,)_learning_rate=adaptive_learning_rate_init=0.001      \n",
       "2  n_neighbors=3                                                                                          \n",
       "3  max_depth=20_n_estimators=200                                                                          \n",
       "4  activation=tanh_alpha=0.01_hidden_layer_sizes=(256,)_learning_rate=constant_learning_rate_init=0.001   \n",
       "5  n_neighbors=3                                                                                          \n",
       "6  max_depth=20_n_estimators=200                                                                          \n",
       "7  activation=tanh_alpha=1_hidden_layer_sizes=(256,)_learning_rate=adaptive_learning_rate_init=0.001      \n",
       "8  n_neighbors=3                                                                                          \n",
       "\n",
       "   train_duration  predict_duration  accuracy features  \n",
       "0  2.295731        0.137406          0.893729  hist1D   \n",
       "1  3.016250        0.029408          0.919472  hist1D   \n",
       "2  0.113536        0.794551          0.925413  hist1D   \n",
       "3  2.252907        0.193570          0.932673  hist2D   \n",
       "4  7.798414        0.101383          0.955116  hist2D   \n",
       "5  0.450569        1.795464          0.933993  hist2D   \n",
       "6  1.201391        0.106719          0.910231  hist3D   \n",
       "7  7.576664        0.009260          0.948515  hist3D   \n",
       "8  0.146073        1.210200          0.920132  hist3D   "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "traffic_signs_hist_results_df[[\"model\",\"params\", \"train_duration\", \"predict_duration\",\"accuracy\", \"features\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_and_save_results(traffic_signs_bovw_results_df,traffic_sign_image_labels_train+traffic_sign_image_labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_duration</th>\n",
       "      <th>predict_duration</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>max_depth=20_n_estimators=200</td>\n",
       "      <td>0.569251</td>\n",
       "      <td>0.103626</td>\n",
       "      <td>0.877228</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>activation=tanh_alpha=0.1_hidden_layer_sizes=(64,)_learning_rate=constant_learning_rate_init=0.001</td>\n",
       "      <td>3.489731</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.882508</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>n_neighbors=5</td>\n",
       "      <td>0.037804</td>\n",
       "      <td>1.285195</td>\n",
       "      <td>0.835644</td>\n",
       "      <td>bovw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  \\\n",
       "0  RandomForrest   \n",
       "1  MLP             \n",
       "2  k-NN            \n",
       "\n",
       "                                                                                               params  \\\n",
       "0  max_depth=20_n_estimators=200                                                                        \n",
       "1  activation=tanh_alpha=0.1_hidden_layer_sizes=(64,)_learning_rate=constant_learning_rate_init=0.001   \n",
       "2  n_neighbors=5                                                                                        \n",
       "\n",
       "   train_duration  predict_duration  accuracy features  \n",
       "0  0.569251        0.103626          0.877228  bovw     \n",
       "1  3.489731        0.001043          0.882508  bovw     \n",
       "2  0.037804        1.285195          0.835644  bovw     "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "traffic_signs_bovw_results_df[[\"model\",\"params\", \"train_duration\", \"predict_duration\",\"accuracy\", \"features\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
