{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29944,
     "status": "ok",
     "timestamp": 1580925698862,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "FVTp72d9RHk6",
    "outputId": "38ebdcd9-03bc-4451-f1ee-9dce78d1147b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "save_path = \"/content/drive/My Drive/mlex3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31524,
     "status": "ok",
     "timestamp": 1580925700450,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "yXagjFyZRAhS",
    "outputId": "5ee8ac9b-bea3-4fd4-c400-1af1f4447a18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Flatten, Activation\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33604,
     "status": "ok",
     "timestamp": 1580925702538,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "iQ4ylGBBRAhZ",
    "outputId": "cf2ffd8e-faad-479e-e631-1a482f5a96cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxhRT8hXRAhc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NUkAtISRAhe"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_images_and_labels(path, file_ending= \"jpg\"):\n",
    "    paths = []\n",
    "    labels = []\n",
    "    for directory in Path(path).glob('*'):\n",
    "        for p in directory.glob(\"*.\" + file_ending):\n",
    "            paths.append(p)\n",
    "            labels.append(directory.name)\n",
    "\n",
    "    return paths, labels\n",
    "\n",
    "\n",
    "fruit_image_paths, fruit_image_labels = get_images_and_labels(\"/content/drive/My Drive/data/FIDS30/\")\n",
    "\n",
    "traffic_sign_image_paths_train, traffic_sign_image_labels_train = get_images_and_labels(\"/content/drive/My Drive/data/TrafficSigns/train\", \"ppm\")\n",
    "traffic_sign_image_paths_test, traffic_sign_image_labels_test = get_images_and_labels(\"/content/drive/My Drive/data/TrafficSigns/test\",\"ppm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aec_sSyRAhh"
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_fruit_images(files, labels, augment = False, batch_size = 16  ): \n",
    "    \n",
    "    np.random.seed(1234)\n",
    "    target_size=(224, 224) # the same as the pretrained VGG net\n",
    "    validation_size = 0.1\n",
    "    test_size = 0.2\n",
    "\n",
    "    data = pd.DataFrame(list(zip(files, labels)),columns=['filename', 'class'],dtype=np.str)\n",
    "    train, test = train_test_split(data, test_size=test_size, random_state=1234)  \n",
    "    \n",
    "    if augment is True:\n",
    "        image_generator = ImageDataGenerator(rescale=1/255.,\n",
    "                                            validation_split=validation_size,\n",
    "                                     rotation_range=20,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True\n",
    "                                     )\n",
    "    else:\n",
    "        image_generator = ImageDataGenerator(rescale=1/255.,\n",
    "                                             validation_split=validation_size)\n",
    "    \n",
    "    train_generator = image_generator.flow_from_dataframe(train, batch_size=batch_size,\n",
    "                                            target_size=target_size,\n",
    "                                            class_mode='categorical',\n",
    "                                            subset='training')\n",
    "    validation_generator = image_generator.flow_from_dataframe(train, batch_size=batch_size,\n",
    "                                          target_size=target_size,\n",
    "                                          class_mode='categorical',\n",
    "                                          subset='validation')\n",
    "\n",
    "    image_generator = ImageDataGenerator(rescale=1/255.,)\n",
    "    \n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(test, batch_size=batch_size,\n",
    "                                           target_size=target_size,\n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False)\n",
    "\n",
    "    return train_generator, test_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57309,
     "status": "ok",
     "timestamp": 1580925726271,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "Du82RkGiRAhj",
    "outputId": "3ca588ca-78b7-4932-c975-80b4a3294fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 699 validated image filenames belonging to 30 classes.\n",
      "Found 77 validated image filenames belonging to 30 classes.\n",
      "Found 195 validated image filenames belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, test_generator, validation_generator = load_and_prepare_fruit_images(fruit_image_paths, fruit_image_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fc3UzEMRAhm"
   },
   "outputs": [],
   "source": [
    "def createVGGNetSelf(input_shape, classes ):\n",
    "   \n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Full Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def createVGGNet(input_shape, classes ):\n",
    "   \n",
    "    model = VGG16(include_top=True, weights=None, input_shape=input_shape, classes=classes)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def createVGGNetPreTrained(input_shape, classes ):\n",
    "   \n",
    "    np.random.seed(1234)\n",
    "    pretrained_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    y = Flatten()(pretrained_model.output)\n",
    "    y = Dense(500, activation=\"relu\")(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    y = Dense(1000, activation=\"relu\")(y)\n",
    "    y = Dense(classes, activation='softmax', name='my_dense_2')(y)\n",
    "    model = Model( pretrained_model.input, y)\n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXbQz4V6RAhp"
   },
   "source": [
    "We are using a VGG16 deeplearning architecture pretrained on the imagenet dataset. \n",
    "We adapted this architecture to fit our data set/classes. See https://towardsdatascience.com/step-by-step-guide-to-using-pretrained-models-in-keras-c9097b647b29 for how to do this. This allows us to train our classifier much faster since we just train the last added Dense layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQMtDRJ1RAhq"
   },
   "outputs": [],
   "source": [
    "def plotConfusionMatrix(y_true, y_pred, classes, name=None, normalize=True,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = np.array(list(classes))[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title='Confusion Matrix',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    size = 6 if normalize else 9\n",
    "    thresh = 0.5 if normalize else cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\", size=size,\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if name is not None:\n",
    "        plt.savefig(save_path+'/figures/' + name + '_cm.png', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def plotTrainingCurve(history, name=None):\n",
    "    sns.set_style('ticks')\n",
    "\n",
    "    hist = history.history\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "    for measure in hist.keys():\n",
    "        epochs = range(1, len(hist[measure]) + 1)\n",
    "        plt.plot(epochs, hist[measure], label=measure)\n",
    "\n",
    "    plt.xticks(epochs)\n",
    "\n",
    "    plt.legend()\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if name is not None:\n",
    "        plt.savefig(save_path+'/figures/' + name + '.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGkCjxSIRAhs"
   },
   "source": [
    "# Train model on non augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 439949,
     "status": "ok",
     "timestamp": 1580926108935,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "LpRf18VhRAht",
    "outputId": "467ab266-455b-4660-8d0e-04d60c3259d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 191s 4s/step - loss: 3.3040 - acc: 0.1569 - val_loss: 2.7019 - val_acc: 0.3636\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 19s 430ms/step - loss: 1.8080 - acc: 0.4770 - val_loss: 1.8127 - val_acc: 0.4805\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 20s 457ms/step - loss: 1.0745 - acc: 0.6721 - val_loss: 1.8938 - val_acc: 0.4416\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 20s 458ms/step - loss: 0.6967 - acc: 0.7877 - val_loss: 1.5230 - val_acc: 0.5584\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 20s 449ms/step - loss: 0.4175 - acc: 0.8709 - val_loss: 1.7086 - val_acc: 0.5455\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 20s 458ms/step - loss: 0.2988 - acc: 0.9092 - val_loss: 1.6890 - val_acc: 0.4805\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 20s 460ms/step - loss: 0.2469 - acc: 0.9291 - val_loss: 1.5058 - val_acc: 0.5714\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 20s 457ms/step - loss: 0.3080 - acc: 0.8991 - val_loss: 1.8855 - val_acc: 0.5325\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 20s 454ms/step - loss: 0.2957 - acc: 0.9129 - val_loss: 2.4297 - val_acc: 0.4675\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 20s 456ms/step - loss: 0.3492 - acc: 0.8934 - val_loss: 2.0847 - val_acc: 0.4805\n"
     ]
    }
   ],
   "source": [
    " \n",
    "input_shape = train_generator.image_shape\n",
    "model = createVGGNetPreTrained(input_shape, len(np.unique(fruit_image_labels)))\n",
    "\n",
    "start_time = time.time()\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=len(train_generator),\n",
    "                                  validation_data=validation_generator,\n",
    "                                  validation_steps=len(validation_generator),\n",
    "                                epochs=10)\n",
    "training_duration = time.time() - start_time\n",
    "\n",
    "model.save(save_path+'/models/fruit_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IrbtIkQRAhx"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgLwZPnzRAhy"
   },
   "source": [
    "# Test non augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GfxrMMPNRAhy"
   },
   "outputs": [],
   "source": [
    "summary = {}\n",
    "model_name = \"Fruits_non_augmented\"\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "prediction_duration =  time.time() - start_time\n",
    "\n",
    "score = accuracy_score(test_generator.classes, predictions.argmax(axis=1))\n",
    "\n",
    "train_data = {}\n",
    "train_data['accuracy_score'] = score\n",
    "train_data['train_time'] = training_duration\n",
    "train_data['train_time'] = prediction_duration\n",
    "summary[model_name] = train_data\n",
    "\n",
    "plotTrainingCurve(model_history, name=model_name)\n",
    "plotConfusionMatrix(test_generator.classes, predictions.argmax(axis=1),\n",
    "                    train_generator.class_indices, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sUpMk2_RAh1"
   },
   "source": [
    "# Train model on augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494237,
     "status": "ok",
     "timestamp": 1580926163240,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "bLJIMvcMN-Gv",
    "outputId": "beead452-7b24-43fc-93bb-319d49be6cb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 699 validated image filenames belonging to 30 classes.\n",
      "Found 77 validated image filenames belonging to 30 classes.\n",
      "Found 195 validated image filenames belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator_augmented, test_generator_augmented, validation_generator_augmented = load_and_prepare_fruit_images(fruit_image_paths, fruit_image_labels, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768506,
     "status": "ok",
     "timestamp": 1580926437518,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "fLeDvSzXRAh2",
    "outputId": "f86ad9f0-5c0c-4db5-9141-783574beec60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 28s 632ms/step - loss: 3.9191 - acc: 0.0936 - val_loss: 2.9314 - val_acc: 0.1039\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 27s 615ms/step - loss: 2.6936 - acc: 0.2101 - val_loss: 2.5290 - val_acc: 0.3377\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 27s 606ms/step - loss: 2.3176 - acc: 0.2966 - val_loss: 2.4754 - val_acc: 0.2987\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 27s 614ms/step - loss: 2.0717 - acc: 0.3675 - val_loss: 2.2096 - val_acc: 0.3506\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 27s 612ms/step - loss: 1.9168 - acc: 0.4189 - val_loss: 1.9201 - val_acc: 0.4416\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 27s 610ms/step - loss: 1.7562 - acc: 0.4428 - val_loss: 1.9108 - val_acc: 0.4545\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 27s 619ms/step - loss: 1.6850 - acc: 0.4732 - val_loss: 1.8446 - val_acc: 0.4675\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 27s 612ms/step - loss: 1.5425 - acc: 0.5100 - val_loss: 1.9418 - val_acc: 0.4416\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 27s 608ms/step - loss: 1.5864 - acc: 0.5086 - val_loss: 1.6015 - val_acc: 0.5195\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 27s 608ms/step - loss: 1.4782 - acc: 0.5359 - val_loss: 1.5849 - val_acc: 0.4805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = train_generator_augmented.image_shape\n",
    "model_augmented = createVGGNetPreTrained(input_shape, len(np.unique(fruit_image_labels)))\n",
    "\n",
    "start_time = time.time()\n",
    "model_augmented_history = model_augmented.fit_generator(train_generator_augmented, steps_per_epoch=len(train_generator_augmented),\n",
    "                                  validation_data=validation_generator_augmented,\n",
    "                                  validation_steps=len(validation_generator_augmented),\n",
    "                                epochs=10)\n",
    "training_duration = time.time() - start_time\n",
    "\n",
    "\n",
    "model_augmented.save(save_path+'/models/fruit_model_augmented.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sqVBBe1tRAh4"
   },
   "source": [
    "# Test on augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOFQYojKRAh5"
   },
   "outputs": [],
   "source": [
    "model_name = \"Fruits_augmented\"\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model_augmented.predict_generator(test_generator_augmented, steps=len(test_generator_augmented))\n",
    "prediction_duration =  time.time() - start_time\n",
    "\n",
    "score = accuracy_score(test_generator_augmented.classes, predictions.argmax(axis=1))\n",
    "\n",
    "train_data = {}\n",
    "train_data['accuracy_score'] = score\n",
    "train_data['train_time'] = training_duration\n",
    "train_data['train_time'] = prediction_duration\n",
    "summary[model_name] = train_data\n",
    "\n",
    "plotTrainingCurve(model_history, name=model_name)\n",
    "plotConfusionMatrix(test_generator.classes, predictions.argmax(axis=1),\n",
    "                    train_generator.class_indices, name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9cMUvPaRAh7"
   },
   "outputs": [],
   "source": [
    "\n",
    "summary_df = pd.DataFrame.from_dict(summary, orient='index')\n",
    "summary_df.to_csv(save_path+'/scores/model_fruits.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 777904,
     "status": "ok",
     "timestamp": 1580926446938,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "1kPec4enRAh-",
    "outputId": "2ad26b1f-9a18-47b2-e44a-91265ece5418"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fruits_non_augmented</th>\n",
       "      <td>0.482051</td>\n",
       "      <td>51.031782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits_augmented</th>\n",
       "      <td>0.507692</td>\n",
       "      <td>6.390636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy_score  train_time\n",
       "Fruits_non_augmented        0.482051   51.031782\n",
       "Fruits_augmented            0.507692    6.390636"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQJY8KFWRAiA"
   },
   "source": [
    "We know that the imagenet dataset contains a lof of different classes including fruits. Thus it is alsready very good a predicting fruit images and thus the good results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uYVu5lSRAiB"
   },
   "source": [
    "# Traffic Sign Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KcAuqlX0RAiC"
   },
   "source": [
    "For the traffic sign data here we don't flip the augemented images, since in real world don't observe flipped signs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_HxQ0cjRAiC"
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_traffic_images(files, labels, augment = False, batch_size = 16  ): \n",
    "    \n",
    "    np.random.seed(1234)\n",
    "    target_size=(224, 224) # the same as the pretrained VGG net\n",
    "    validation_size = 0.1\n",
    "    test_size = 0.2\n",
    "\n",
    "    data = pd.DataFrame(list(zip(files, labels)),columns=['filename', 'class'],dtype=np.str)\n",
    "    train, test = train_test_split(data, test_size=test_size, random_state=1234)  \n",
    "    \n",
    "    if augment is True:\n",
    "        image_generator = ImageDataGenerator(rescale=1/255.,\n",
    "                                            validation_split=validation_size,\n",
    "                                     rotation_range=20,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True)\n",
    "    else:\n",
    "        image_generator = ImageDataGenerator(rescale=1/255.,\n",
    "                                             validation_split=validation_size)\n",
    "    \n",
    "    train_generator = image_generator.flow_from_dataframe(train, batch_size=batch_size,\n",
    "                                            target_size=target_size,\n",
    "                                            class_mode='categorical',\n",
    "                                            subset='training')\n",
    "    validation_generator = image_generator.flow_from_dataframe(train, batch_size=batch_size,\n",
    "                                          target_size=target_size,\n",
    "                                          class_mode='categorical',\n",
    "                                          subset='validation')\n",
    "\n",
    "    image_generator = ImageDataGenerator(rescale=1/255.,)\n",
    "    \n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(test, batch_size=batch_size,\n",
    "                                           target_size=target_size,\n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False)\n",
    "\n",
    "    return train_generator, test_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G40_w6_6RAiE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 783974,
     "status": "ok",
     "timestamp": 1580926453035,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "pt2qLxpORAiG",
    "outputId": "b29d21c6-c332-461c-b1d4-3c1909c820a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4362 validated image filenames belonging to 9 classes.\n",
      "Found 484 validated image filenames belonging to 9 classes.\n",
      "Found 1212 validated image filenames belonging to 9 classes.\n",
      "Found 4362 validated image filenames belonging to 9 classes.\n",
      "Found 484 validated image filenames belonging to 9 classes.\n",
      "Found 1212 validated image filenames belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, test_generator, validation_generator = load_and_prepare_traffic_images(\n",
    "    traffic_sign_image_paths_train+traffic_sign_image_paths_test, \n",
    "    traffic_sign_image_labels_train+traffic_sign_image_labels_test)\n",
    "\n",
    "train_generator_augmented, test_generator_augmented, validation_generator_augmented = load_and_prepare_traffic_images(\n",
    "    traffic_sign_image_paths_train+traffic_sign_image_paths_test, \n",
    "    traffic_sign_image_labels_train+traffic_sign_image_labels_test,\n",
    "    augment = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-YZTMKdRAiJ"
   },
   "source": [
    "# Train Traffic sign on non augmented data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2336568,
     "status": "ok",
     "timestamp": 1580928005639,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "CEPVdgyyRAiK",
    "outputId": "a47b1020-41fb-4ec3-eda4-33dd8b1e07d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "273/273 [==============================] - 1314s 5s/step - loss: 0.3579 - acc: 0.8958 - val_loss: 0.2127 - val_acc: 0.9215\n",
      "Epoch 2/10\n",
      "273/273 [==============================] - 25s 91ms/step - loss: 0.1424 - acc: 0.9575 - val_loss: 0.0926 - val_acc: 0.9669\n",
      "Epoch 3/10\n",
      "273/273 [==============================] - 25s 93ms/step - loss: 0.1141 - acc: 0.9658 - val_loss: 0.0312 - val_acc: 0.9959\n",
      "Epoch 4/10\n",
      "273/273 [==============================] - 26s 95ms/step - loss: 0.0693 - acc: 0.9789 - val_loss: 0.0916 - val_acc: 0.9669\n",
      "Epoch 5/10\n",
      "273/273 [==============================] - 26s 97ms/step - loss: 0.1274 - acc: 0.9636 - val_loss: 0.0546 - val_acc: 0.9855\n",
      "Epoch 6/10\n",
      "273/273 [==============================] - 27s 97ms/step - loss: 0.0857 - acc: 0.9746 - val_loss: 0.0365 - val_acc: 0.9855\n",
      "Epoch 7/10\n",
      "273/273 [==============================] - 26s 96ms/step - loss: 0.0862 - acc: 0.9712 - val_loss: 0.0142 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      "273/273 [==============================] - 26s 97ms/step - loss: 0.0784 - acc: 0.9789 - val_loss: 0.0150 - val_acc: 0.9979\n",
      "Epoch 9/10\n",
      "273/273 [==============================] - 26s 97ms/step - loss: 0.0761 - acc: 0.9757 - val_loss: 0.0226 - val_acc: 0.9959\n",
      "Epoch 10/10\n",
      "273/273 [==============================] - 26s 97ms/step - loss: 0.0476 - acc: 0.9840 - val_loss: 0.0401 - val_acc: 0.9835\n"
     ]
    }
   ],
   "source": [
    " \n",
    "input_shape = train_generator.image_shape\n",
    "model = createVGGNetPreTrained(input_shape, len(np.unique(traffic_sign_image_labels_train+traffic_sign_image_labels_test)))\n",
    "\n",
    "start_time = time.time()\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=len(train_generator),\n",
    "                                  validation_data=validation_generator,\n",
    "                                  validation_steps=len(validation_generator),\n",
    "                                epochs=10)\n",
    "training_duration = time.time() - start_time\n",
    "\n",
    "model.save(save_path+'/models/traffic_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hz_x2f6ERAiN"
   },
   "source": [
    "Test on non Augmented Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TgltaLERAiN"
   },
   "outputs": [],
   "source": [
    "summary = {}\n",
    "model_name = \"Traffic_Signs_non_augmented\"\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "prediction_duration =  time.time() - start_time\n",
    "\n",
    "score = accuracy_score(test_generator.classes, predictions.argmax(axis=1))\n",
    "\n",
    "train_data = {}\n",
    "train_data['accuracy_score'] = score\n",
    "train_data['train_time'] = training_duration\n",
    "train_data['train_time'] = prediction_duration\n",
    "summary[model_name] = train_data\n",
    "\n",
    "plotTrainingCurve(model_history, name=model_name)\n",
    "plotConfusionMatrix(test_generator.classes, predictions.argmax(axis=1),\n",
    "                    train_generator.class_indices, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kueKM3faRAiP"
   },
   "source": [
    "# Train on augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3336456,
     "status": "ok",
     "timestamp": 1580929005568,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "ChS3BKNgRAiQ",
    "outputId": "982b5c88-c0e6-4296-a8aa-47a2345574ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "273/273 [==============================] - 60s 219ms/step - loss: 0.6315 - acc: 0.8004 - val_loss: 0.3466 - val_acc: 0.8802\n",
      "Epoch 2/10\n",
      "273/273 [==============================] - 58s 211ms/step - loss: 0.3889 - acc: 0.8757 - val_loss: 0.2768 - val_acc: 0.9029\n",
      "Epoch 3/10\n",
      "273/273 [==============================] - 57s 210ms/step - loss: 0.3341 - acc: 0.8929 - val_loss: 0.2530 - val_acc: 0.9153\n",
      "Epoch 4/10\n",
      "273/273 [==============================] - 57s 210ms/step - loss: 0.2906 - acc: 0.9065 - val_loss: 0.1549 - val_acc: 0.9463\n",
      "Epoch 5/10\n",
      "273/273 [==============================] - 56s 207ms/step - loss: 0.2729 - acc: 0.9132 - val_loss: 0.1896 - val_acc: 0.9442\n",
      "Epoch 6/10\n",
      "273/273 [==============================] - 57s 207ms/step - loss: 0.2718 - acc: 0.9123 - val_loss: 0.2119 - val_acc: 0.9298\n",
      "Epoch 7/10\n",
      "273/273 [==============================] - 57s 207ms/step - loss: 0.2593 - acc: 0.9084 - val_loss: 0.1916 - val_acc: 0.9277\n",
      "Epoch 8/10\n",
      "273/273 [==============================] - 57s 210ms/step - loss: 0.2442 - acc: 0.9195 - val_loss: 0.1138 - val_acc: 0.9690\n",
      "Epoch 9/10\n",
      "273/273 [==============================] - 56s 206ms/step - loss: 0.2224 - acc: 0.9323 - val_loss: 0.1721 - val_acc: 0.9380\n",
      "Epoch 10/10\n",
      "273/273 [==============================] - 57s 207ms/step - loss: 0.2229 - acc: 0.9272 - val_loss: 0.1374 - val_acc: 0.9587\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = train_generator_augmented.image_shape\n",
    "model_augmented = createVGGNetPreTrained(input_shape, len(np.unique(traffic_sign_image_labels_train+traffic_sign_image_labels_test)))\n",
    "\n",
    "start_time = time.time()\n",
    "model_augmented_history = model_augmented.fit_generator(train_generator_augmented, steps_per_epoch=len(train_generator_augmented),\n",
    "                                  validation_data=validation_generator_augmented,\n",
    "                                  validation_steps=len(validation_generator_augmented),\n",
    "                                epochs=10)\n",
    "training_duration = time.time() - start_time\n",
    "\n",
    "\n",
    "model_augmented.save(save_path+'/models/traffic_signs_model_augmented.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obMrhAj9RAiS"
   },
   "source": [
    "# Test on Augmented Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEdrUYlbRAiS"
   },
   "outputs": [],
   "source": [
    "model_name = \"Traffic_Signs_Augmented\"\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = model_augmented.predict_generator(test_generator_augmented, steps=len(test_generator_augmented))\n",
    "prediction_duration =  time.time() - start_time\n",
    "\n",
    "score = accuracy_score(test_generator_augmented.classes, predictions.argmax(axis=1))\n",
    "\n",
    "train_data = {}\n",
    "train_data['accuracy_score'] = score\n",
    "train_data['train_time'] = training_duration\n",
    "train_data['train_time'] = prediction_duration\n",
    "summary[model_name] = train_data\n",
    "\n",
    "plotTrainingCurve(model_augmented_history, name=model_name)\n",
    "plotConfusionMatrix(test_generator.classes, predictions.argmax(axis=1),\n",
    "                    train_generator.class_indices, name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1UAp8ICRAiV"
   },
   "outputs": [],
   "source": [
    "\n",
    "summary_df = pd.DataFrame.from_dict(summary, orient='index')\n",
    "summary_df.to_csv(save_path+'/scores/models_traffic_signs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3344618,
     "status": "ok",
     "timestamp": 1580929013751,
     "user": {
      "displayName": "Patrick Fürst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAKHKDjgWf0CJ49rruP-hKlkeh872k3-j40-Uqf4Q=s64",
      "userId": "08955009347853928908"
     },
     "user_tz": -60
    },
    "id": "SfPxiggdRAiX",
    "outputId": "da1173fe-ce0c-4ae4-ab2d-8805056ee9d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Traffic_Signs_non_augmented</th>\n",
       "      <td>0.995050</td>\n",
       "      <td>412.113385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic_Signs_Augmented</th>\n",
       "      <td>0.971122</td>\n",
       "      <td>6.864012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy_score  train_time\n",
       "Traffic_Signs_non_augmented        0.995050  412.113385\n",
       "Traffic_Signs_Augmented            0.971122    6.864012"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deeplearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
