---
title: "Machine Learning with caret in R"
subtitle: "for Exercises"
author: "Eszter Katalin Bognar"
date: "02-06-2020"
output: pdf_document
---

# Regression models: fitting them and evaluating their performance

# In-sample RMSE 
```{r, echo=T}
library(caret)
# Fit lm model: model
model <- lm(price ~., diamonds)

# Predict on full data: p
p <- predict(model)

# Compute errors: error
error <- p - diamonds$price

# Calculate RMSE
RMSE <- sqrt(mean(error^2))
RMSE
```

# Out-of-sample RMSE

## Randomly order the data frame
```{r, echo=T}
# Set seed
set.seed(42)

# Shuffle row indices: rows
rows <- sample(nrow(diamonds))

# Randomly order data
shuffled_diamonds <- diamonds[rows, ]
```

## 80/20 split
```{r, echo=T}
# Determine row to split on: split
split <- round(nrow(diamonds) * 0.80)

# Create train
train <- diamonds[1:split,]

# Create test
test <- diamonds[(split + 1):nrow(diamonds), ]
```

## Predict on test set
```{r, echo=T}
# Fit lm model on train: model
model <- lm(price ~ ., train)

# Predict on test: p
p <- predict(model,test)
```

## Calculate test set RMSE 
```{r, echo=T}
# Compute errors: error
error <- p-test$price

# Calculate RMSE
print(sqrt(mean(error^2)))
```

# Cross-validation

## 10-fold cross-validation
```{r, echo=T}
# Fit lm model using 10-fold CV: model
model <- train(
  price ~.,
  diamonds,
  method = "lm",
  trControl = trainControl(
    method = "cv", 
    number = 10,
    verboseIter = FALSE
  )
)
```

## 5 x 5-fold cross-validation
```{r, echo=T}
# Fit lm model using 5 x 5-fold CV: model
model <- train(
  price ~., 
  diamonds,
  method = "lm",
  trControl = trainControl(
    method = "repeatedcv", 
    number = 5,
    repeats = 5, 
    verboseIter = FALSE
  )
)
```

# train/test split

## 60/40 split on Sonar dataset
```{r, echo=T}
library(mlbench)
data(Sonar)
# Get the number of observations
n_obs <- nrow(Sonar)

# Shuffle row indices: permuted_rows
permuted_rows <- sample(n_obs)

# Randomly order data: Sonar
Sonar_shuffled <- Sonar[permuted_rows, ]

# Identify row to split on: split
split <- round(nrow(Sonar_shuffled) * 0.60)

# Create train
train <- Sonar_shuffled[1:split,]

# Create test
test <- Sonar_shuffled[(split + 1):nrow(Sonar_shuffled), ]
```

# model fit

```{r, echo=T}
model<-glm(Class~.,family="binomial", train)
# Predict on test: p
p<-predict(model,test,type="response")
```

# Confusion matrix

```{r, echo=T}
# If p exceeds threshold of 0.5, M else R: m_or_r
m_or_r <- ifelse(p > 0.5, "M", "R")

# Convert to factor: p_class
p_class <- factor(m_or_r, levels = levels(test[["Class"]]))

# Create confusion matrix
confusionMatrix(p_class, test[["Class"]])
```

# Class probabilities and predictions  - Evaluating classification tresholds

## ROC curve

```{r, echo=T,fig.width=6,fig.height=4}
library(caTools)
# Predict on test: p
p<-predict(model,test,type="response")

# Make ROC curve
colAUC(p, test[["Class"]], plotROC = TRUE)
```

## Area under the curve (AUC)

Customizing and using trainControl

```{r, echo=T,eval=F}
# Create trainControl object: myControl
myControl <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = FALSE
)
# Train glm with custom trainControl: model
model<-train(method="glm",data=Sonar,Class~.,trControl=myControl)

# Print model to console
print(model)
```

# Random forest model

## fitting RF

```{r, echo=T}
# obtain the dataset
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
wine <- read.csv(url, header = TRUE, sep = ";")
# Fit random forest: model
model <- train(
  quality~.,
  tuneLength = 1,
  data = wine, 
  method = "ranger",
  trControl = trainControl(
    method = "cv", 
    number = 5, 
    verboseIter = FALSE
  )
)
```

# Hyperparameter tuning

## Try a longer tune length

```{r, echo=T, fig.width=6, fig.height=4}
# Fit random forest: model
model <- train(
  quality~.,
  tuneLength = 3,
  data = wine, 
  method = "ranger",
  trControl = trainControl(
    method = "cv", 
    number = 5, 
    verboseIter = FALSE
  )
)

# Print model to console
print(model)

# Plot model
plot(model)
```

## Custom tuning using tuneGrid

```{r, echo=T}
tuneGrid <- data.frame(
  .mtry = c(2, 3, 7),
  .splitrule = "variance",
  .min.node.size = 5
)
```

## Print maximum ROC statistic

```{r, echo=T}
max(model[["results"]][["ROC"]])
```

## glmnet with custom trainControl and tuning

```{r, echo=T, eval=F}
# Train glmnet with custom trainControl and tuning: model
model <- train(
  y~., 
  data = overfit,
  tuneGrid = expand.grid(
    alpha = 0:1,
    lambda = seq(0.0001,1,length=20)
  ),
  method = "glmnet",
  trControl = myControl
)
```

# Handling missing values

## Median inputation

```{r, echo=T, eval=F}
library(OneR)
data(breastcancer)
breast_cancer_y <- breastcancer$Class
breast_cancer_x <- breastcancer[,-10]
str(breast_cancer_y)
model <- train(
  x = breast_cancer_x, y = breast_cancer_y,
  method = "glm",
  trControl = myControl,
  preProcess = "medianImpute"
)
```

## KNN inputation

```{r, echo=T, eval=F}
# Apply KNN imputation: knn_model
library(RANN)
knn_model <- train(
  x = breast_cancer_x, 
  y = breast_cancer_y,
  method = "glm",
  trControl = myControl,
  preProcess = "knnImpute"
)
```

# Other preprocessing steps

## Combining preprocessing methods

```{r, echo=T, eval=F}
# Update model with standardization
model <- train(
  x = breast_cancer_x, 
  y = breast_cancer_y,
  method = "glm",
  trControl = myControl,
  preProcess = c("medianImpute", "center", "scale")
)
```

# Handling low-information predictors

## Remove near zero variance predictors

```{r, echo=T, eval=T}
url <- "https://assets.datacamp.com/production/course_1048/datasets/BloodBrain.RData"
download.file(url, "./BloodBrain.RData")
load("./BloodBrain.RData")
# Identify near zero variance predictors: remove_cols
remove_cols <- nearZeroVar(bloodbrain_x, names = TRUE, 
                           freqCut = 2, uniqueCut = 20)

# Get all column names from bloodbrain_x: all_cols
all_cols <- names(bloodbrain_x)

# Remove from data: bloodbrain_x_small
bloodbrain_x_small <- bloodbrain_x[ , setdiff(all_cols, remove_cols)]
print(model)
```

## Principle components analysis (PCA)

```{r, echo=T, eval=T}
# Fit glm model using PCA: model
model <- train(
  x = bloodbrain_x, 
  y = bloodbrain_y,
  method = "glm", 
  preProcess = "pca"
)
print(model)
```

# Applying trainControl

## Custom train/test split

```{r, echo=T, eval=T}
url <- "https://assets.datacamp.com/production/course_1048/datasets/Churn.RData"
download.file(url, "./Churn.RData")
load("./Churn.RData")
# Create custom indices: myFolds
myFolds <- createFolds(churn_y, k = 5)

# Create reusable trainControl object: myControl
myControl <- trainControl(
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = FALSE,
  savePredictions = TRUE,
  index = myFolds
)
```

# glmnet and rf models

```{r, echo=T, eval=F}
model_glmnet <- train(
x = churn_x, y = churn_y,
metric = "ROC",
method = "glmnet",
trControl = myControl
)

model_rf <- train(
x = churn_x, y = churn_y,
metric = "ROC",
method = "ranger",
trControl = myControl
)
```

# Comparing models

```{r, echo=T, eval=F}
# Create model_list
model_list <- list(item1 = model_glmnet, item2 = model_rf)

# Pass model_list to resamples(): resamples
resamples <- resamples(model_list)

# Summarize the results
summary(resamples)
```

# box-and-whisker plot

```{r, echo=T, eval=F, fig.width=6, fig.height=4}
# Create bwplot
bwplot(resamples,metric = "ROC")
```

# Scatterplot

```{r, echo=T, eval=F, fig.width=6, fig.height=4}
# Create xyplot
xyplot(resamples,metric = "ROC")
```

# Ensembling models

```{r, echo=T, eval=F}
library(caretEnsemble)
# Create ensemble model: stack
stack <- caretStack(all.models = model_list, method = "glm")
# Look at summary
summary(stack)
```
</div></pre>